{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0fe06-44e6-412a-a0a6-37258f8f9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#### 해당 파일은 데이터셋 전처리 및 파일 추출 전용 입니다.\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb382b0-6e07-43bc-941b-a82478fa8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import json\n",
    "import folium\n",
    "%matplotlib inline\n",
    "# 한글 설정\n",
    "# pip install koreanize_matplotlib\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "root = 'C:/workspace/python/project/data/'\n",
    "# root = 'G:/workspace/python/python_project/data/'\n",
    "\n",
    "# 구글드라이브 : https://drive.google.com/drive/folders/1zIzm1o8-3uxcWSU2DoWpB8aV0Oxdfz_P?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca448c-1305-4f0a-8fc3-64462175a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### 데이터 로드 ######################################\n",
    "'''\n",
    "서울시 집값 데이터 프레임\n",
    "'''\n",
    "seoul_2015_df = pd.read_csv(root + '부동산_Data/부동산_2015.csv', encoding = 'cp949')\n",
    "seoul_2016_df = pd.read_csv(root + '부동산_Data/부동산_2016.csv', encoding = 'cp949')\n",
    "seoul_2017_df = pd.read_csv(root + '부동산_Data/부동산_2017.csv', encoding = 'cp949')\n",
    "seoul_2018_df = pd.read_csv(root + '부동산_Data/부동산_2018.csv', encoding = 'cp949')\n",
    "seoul_2019_df = pd.read_csv(root + '부동산_Data/부동산_2019.csv', encoding = 'cp949')\n",
    "seoul_2020_df = pd.read_csv(root + '부동산_Data/부동산_2020.csv', encoding = 'cp949')\n",
    "seoul_2021_df = pd.read_csv(root + '부동산_Data/부동산_2021.csv', encoding = 'cp949')\n",
    "seoul_2022_df = pd.read_csv(root + '부동산_Data/부동산_2022.csv', encoding = 'cp949')\n",
    "seoul_2023_df = pd.read_csv(root + '부동산_Data/부동산_2023.csv', encoding = 'cp949')\n",
    "\n",
    "# dict_keys(['2019년 12월 31일 기준', '2020년 12월 31일 기준', '2021년 12월 31일 기준', '2022년 12월 31일 기준', '2023년 12월 4일 기준'])\n",
    "all_bus_stop_dict = pd.read_excel(root + '교통_Data/버스_정류소현황(2019~2023년).xlsx', sheet_name=None)\n",
    "bus_stop_address_df = pd.read_excel(root + '교통_Data/서울시버스정류소위치정보(20241110).xlsx')\n",
    "\n",
    "'''\n",
    "유통업체 데이터 프레임\n",
    "'''\n",
    "distributor_2015_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2015.xlsx', header=None)\n",
    "distributor_2016_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2016.xlsx', header=None)\n",
    "distributor_2017_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2017.xlsx', header=None)\n",
    "distributor_2018_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2018.xlsx', header=None)\n",
    "distributor_2019_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2019.xlsx', header=None)\n",
    "distributor_2020_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2020.xlsx', header=None)\n",
    "\n",
    "distributor_2021_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2021.xlsx', header=None)\n",
    "distributor_2022_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2022.xlsx', header=None)\n",
    "distributor_2023_df = pd.read_excel(root + '유통업체_Data/유통업체현황_2023.xlsx', header=None)\n",
    "\n",
    "'''\n",
    "버스 정류장 데이터 프레임\n",
    "'''\n",
    "bus_stop_2019_df = all_bus_stop_dict['2019년 12월 31일 기준']\n",
    "bus_stop_2020_df = all_bus_stop_dict['2020년 12월 31일 기준']\n",
    "bus_stop_2021_df = all_bus_stop_dict['2021년 12월 31일 기준']\n",
    "bus_stop_2022_df = all_bus_stop_dict['2022년 12월 31일 기준']\n",
    "bus_stop_2023_df = all_bus_stop_dict['2023년 12월 4일 기준']\n",
    "\n",
    "'''\n",
    "지하철 데이터 프레임\n",
    "'''\n",
    "train_2015_df = pd.read_csv(root + '교통_Data/서울시 지역별 지하철역 정보_2015.csv', encoding = 'cp949')\n",
    "train_2020_df = pd.read_csv(root + '교통_Data/서울시 지역별 지하철역 정보_2020.csv', encoding = 'cp949')\n",
    "train_2021_df = pd.read_csv(root + '교통_Data/서울시 지역별 지하철역 정보_2021.csv', encoding = 'cp949')\n",
    "train_2022_df = pd.read_csv(root + '교통_Data/서울시 지역별 지하철역 정보_2022.csv', encoding = 'cp949')\n",
    "train_2023_df = pd.read_csv(root + '교통_Data/서울시 지역별 지하철역 정보_2023.csv', encoding = 'cp949')\n",
    "\n",
    "'''\n",
    "인구수 데이터 프레임\n",
    "'''\n",
    "population_2015_2020_df = pd.read_csv(root + '인구수_Data/인구수_2015 ~ 2020.csv', encoding = 'cp949')\n",
    "population_df = pd.read_csv(root + '인구수_Data/인구수.csv', encoding = 'cp949')\n",
    "\n",
    "'''\n",
    "공원 데이터 프레임\n",
    "'''\n",
    "park_2015_df = pd.read_excel(root + '공원_Data/공원현황_2015.xlsx', header=None)\n",
    "park_2016_df = pd.read_excel(root + '공원_Data/공원현황_2016.xlsx', header=None)\n",
    "park_2017_df = pd.read_excel(root + '공원_Data/공원현황_2017.xlsx', header=None)\n",
    "park_2018_df = pd.read_excel(root + '공원_Data/공원현황_2018.xlsx', header=None)\n",
    "park_2019_df = pd.read_excel(root + '공원_Data/공원현황_2019.xlsx', header=None)\n",
    "park_2020_df = pd.read_excel(root + '공원_Data/공원현황_2020.xlsx', header=None)\n",
    "\n",
    "park_2021_df = pd.read_excel(root + '공원_Data/공원현황_2021.xlsx', header=None)\n",
    "park_2022_df = pd.read_excel(root + '공원_Data/공원현황_2022.xlsx', header=None)\n",
    "park_2023_df = pd.read_excel(root + '공원_Data/공원현황_2023.xlsx', header=None)\n",
    "\n",
    "'''\n",
    "의료기관 데이터 프레임\n",
    "'''\n",
    "medical_2015_df = pd.read_excel(root + '의료기관_Data/의료기관_2015.xlsx', header=None)\n",
    "medical_2016_df = pd.read_excel(root + '의료기관_Data/의료기관_2016.xlsx', header=None)\n",
    "medical_2017_df = pd.read_excel(root + '의료기관_Data/의료기관_2017.xlsx', header=None)\n",
    "medical_2018_df = pd.read_excel(root + '의료기관_Data/의료기관_2018.xlsx', header=None)\n",
    "medical_2019_df = pd.read_excel(root + '의료기관_Data/의료기관_2019.xlsx', header=None)\n",
    "medical_2020_df = pd.read_excel(root + '의료기관_Data/의료기관_2020.xlsx', header=None)\n",
    "\n",
    "medical_2021_df = pd.read_excel(root + '의료기관_Data/의료기관_2021.xlsx', header=None)\n",
    "medical_2022_df = pd.read_excel(root + '의료기관_Data/의료기관_2022.xlsx', header=None)\n",
    "medical_2023_df = pd.read_excel(root + '의료기관_Data/의료기관_2023.xlsx', header=None)\n",
    "\n",
    "'''\n",
    "개발계획 데이터 프레임\n",
    "'''\n",
    "develop_2015_df = pd.read_csv(root + '부동산_Data/개발계획2015.csv', encoding='cp949', header=None)\n",
    "develop_2016_df = pd.read_csv(root + '부동산_Data/개발계획2016.csv', encoding='cp949', header=None)\n",
    "develop_2017_df = pd.read_csv(root + '부동산_Data/개발계획2017.csv', encoding='cp949', header=None)\n",
    "develop_2018_df = pd.read_csv(root + '부동산_Data/개발계획2018.csv', encoding='cp949', header=None)\n",
    "develop_2019_df = pd.read_csv(root + '부동산_Data/개발계획2019.csv', encoding='cp949', header=None)\n",
    "develop_2020_df = pd.read_csv(root + '부동산_Data/개발계획2020.csv', encoding='cp949', header=None)\n",
    "\n",
    "develop_2021_df = pd.read_csv(root + '부동산_Data/개발계획2021.csv', encoding='cp949', header=None)\n",
    "develop_2022_df = pd.read_csv(root + '부동산_Data/개발계획2022.csv', encoding='cp949', header=None)\n",
    "develop_2023_df = pd.read_csv(root + '부동산_Data/개발계획2023.csv', encoding='cp949', header=None)\n",
    "\n",
    "'''\n",
    "건축거래 현황 데이터 프레임\n",
    "'''\n",
    "house_transaction_2015_2020_df = pd.read_csv(root + '주거실태_Data/행정구역별_건축물거래현황_2015 ~ 2020.csv', encoding='cp949', header=None)\n",
    "house_transaction_df = pd.read_csv(root + '주거실태_Data/행정구역별_건축물거래현황_20241126100629.csv', encoding='cp949', header=None)\n",
    "\n",
    "'''\n",
    "수요/공급지수 데이터 프레임\n",
    "'''\n",
    "buysell_2015_2020_df = pd.read_csv(root + '수요공급_Data/지역별_매매동향_2015~2020.csv', header=None, encoding='cp949')\n",
    "buysell_df = pd.read_csv(root + '수요공급_Data/지역별_매매동향.csv', header=None, encoding='cp949')\n",
    "\n",
    "'''\n",
    "주거실태 데이터 프레임\n",
    "'''\n",
    "abode_house_2015_2020_category = pd.read_csv(root + '주거실태_Data/주택의_종류별_주택__읍면동_연도_끝자리_0__5___시군구_그_외_연도__2015 ~ 2020.csv', encoding = 'cp949')\n",
    "abode_house_category = pd.read_csv(root + '주거실태_Data/주택의_종류별_주택__읍면동_연도_끝자리_0__5___시군구_그_외_연도__20241120174542.csv', encoding = 'cp949')\n",
    "\n",
    "'''\n",
    "매매가격지수\n",
    "'''\n",
    "# 기준시점과 매기 조사되는 조사시점의 가격비를 이용하여 기준시점이 100인 수치로 환산한 값을 의미\n",
    "# 본 조사에서는 전월비와 전년 말비를 제공, 제공 산식을 활용하여 \n",
    "# 원하는 두 시점의 가격 변동률을 구할 수 있음.\n",
    "# 변동률(%) = {(110 - 105) / 105}X 100 = 4.76퍼센트(%)\n",
    "\n",
    "# 변동률(p) = 110 - 105 = 5포인트(p)\n",
    "priceRelative_2015_2020_df = pd.read_csv(root + '수요공급_Data/매매가격지수_주택종합_2015~2020.csv',  encoding='cp949')\n",
    "priceRelative_df = pd.read_csv(root + '수요공급_Data/매매가격지수_주택종합.csv',  encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4065bca-dbf9-46b9-9979-37cc819c387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "0 행 삭제 클래스\n",
    "'''\n",
    "class ManagedDataFrame:\n",
    "    def __init__(self, name, df):\n",
    "        self.name = name\n",
    "        self.df = df\n",
    "        self.row_deleted = False  # 플래그 초기화\n",
    "\n",
    "    def delete_row_once(self):\n",
    "        if not self.row_deleted and 0 in self.df.index:\n",
    "            self.df = self.df.drop(0)\n",
    "            self.row_deleted = True\n",
    "            print(f\"{self.name}: 0행이 삭제되었습니다.\")\n",
    "        else:\n",
    "            print(f\"{self.name}: 삭제 작업이 이미 완료되었거나 0행이 없습니다.\")\n",
    "\n",
    "    # 객체 출력 시 사용자 정의 내용 반환\n",
    "    def __repr__(self):\n",
    "        return f\"ManagedDataFrame(name={self.name}, row_deleted={self.row_deleted}, df=\\n{self.df}\\n)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa2553-58ab-4899-a6d7-12bbb147eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### 전처리 함수 작성 #######################################\n",
    "'''\n",
    "서울시 집값 전처리 함수 (행정구 별 평균시세)\n",
    "'''\n",
    "def precleaning_seoul(df) :\n",
    "  df = df.groupby(['접수연도', '자치구명'])['물건금액(만원)'].mean().reset_index()\n",
    "  df = df.rename(columns = {'접수연도' : '연도', '자치구명' : '구', '물건금액(만원)' : '평균시세'})\n",
    "  df['평균시세'] = round(df['평균시세'], 2)\n",
    "  return df\n",
    "\n",
    "'''\n",
    "유통업체 전처리 함수\n",
    "'''\n",
    "def precleaning_distributor(df) :\n",
    "  # 컬럼명 지정\n",
    "  df.columns = df.iloc[1] + '_' + df.iloc[3]\n",
    "  df.columns = df.columns.str.strip()\n",
    "  # 쓸모없는 행 삭제\n",
    "  df = df.iloc[4:].reset_index(drop=True)\n",
    "  # 쓸모없는 열 삭제\n",
    "  df = df.drop(columns = ['동별(1)_동별(1)'])\n",
    "  \n",
    "  # 컬럼명 보기 쉽게 변경\n",
    "  df = df.rename(columns = {'동별(2)_동별(2)' : '구'})\n",
    "  columns = []\n",
    "  for column in df.columns : \n",
    "    column = column.split(' (')\n",
    "    columns.append(column[0])\n",
    "  df.columns = columns\n",
    "  return df\n",
    "\n",
    "'''\n",
    "버스 전처리 함수\n",
    "'''\n",
    "def precleaning_bus(df) :\n",
    "  # 연도를 보기쉽게 바꾸기 위해 앞 4글자만 추출\n",
    "  year = df['기준일'].astype(str).str[:4]\n",
    "  \n",
    "  # 추출한 값으로 변경\n",
    "  df['기준일'] = year\n",
    "  \n",
    "  # 컬럼명 통일\n",
    "  df = df.rename(columns = {'기준일' : '연도', '행정구명' : '구'})\n",
    "  \n",
    "  # 버스 정보와 위치정보 병합\n",
    "  df = pd.merge(df, bus_stop_address_df[['ARS_ID', 'X좌표', 'Y좌표']], \n",
    "                              left_on='ARS-ID', right_on='ARS_ID', how='left')\n",
    "  # ARS_ID 중복 컬럼 제거\n",
    "  df.drop(columns=['ARS_ID'], inplace=True)\n",
    "\n",
    "  # 이상한 값 변경\n",
    "  idx = df[df['X좌표'] == 126.457230].index[0]\n",
    "\n",
    "  df.loc[idx, 'X좌표'] = 127.037725\n",
    "  df.loc[idx, 'Y좌표'] = 37.613705\n",
    "\n",
    "  df['정류소명'] = df['정류소명'].replace({'\\u2024': ''}, regex=True)\n",
    "  df['정류소명'] = df['정류소명'].replace({'\\u2027': ''}, regex=True)\n",
    "  return df\n",
    "\n",
    "'''\n",
    "지하철 전처리 함수\n",
    "'''\n",
    "def precleaning_train(df) :\n",
    "  df.columns = ['구', '해당역(호선)', '역개수']\n",
    "  filtered_df = df[df['구'].isin(seoul_2021_avg_df['구'])]\n",
    "  return filtered_df\n",
    "\n",
    "'''\n",
    "인구수 전처리 함수\n",
    "'''\n",
    "def precleaning_population(df, choice) :\n",
    "  year = df.columns.str.contains(choice)\n",
    "  year[0] = True\n",
    "  \n",
    "  tmp_df = df.loc[:, year]\n",
    "  columns_name = tmp_df.iloc[0].values\n",
    "  tmp_df.columns = columns_name\n",
    "  tmp_df = tmp_df.drop(0)\n",
    "  tmp_df = tmp_df.rename(columns = {'행정구역별(읍면동)' : '구'})\n",
    "  columns_name = tmp_df.columns[1:]\n",
    "  \n",
    "  for idx, column in enumerate(columns_name) :\n",
    "    tmp_df = tmp_df.rename(columns = {column : column.split(' ')[0]})\n",
    "  \n",
    "  return tmp_df\n",
    "\n",
    "'''\n",
    "공원 데이터 전처리\n",
    "'''\n",
    "def preclearning_park(df, year):\n",
    "  # 컬럼명 변경\n",
    "  # 2 ~ 5 번 컬럼명을 첫 번째 행 데이터로 변경\n",
    "  columns_name = df.columns[1:5]\n",
    "  for column in columns_name :\n",
    "    name = df[column][1] + '_' + df[column][4]\n",
    "    df = df.rename(columns = {column : name})\n",
    "  \n",
    "  # 5 ~ 10 번 컬럼명을 1, 4 번째 행 데이터로 변경\n",
    "  columns_name = df.columns[5 : 11]\n",
    "  for column in columns_name :\n",
    "    name = df[column][1] + '_' + df[column][4]\n",
    "    df = df.rename(columns = {column : name})  \n",
    "  \n",
    "  \n",
    "  # 11번 이후 컬럼명을 3, 4번째 행 데이터로 변경\n",
    "  columns_name = df.columns[11:]\n",
    "  for column in columns_name :\n",
    "    name = df[column][3] + '_' + df[column][4]\n",
    "    df = df.rename(columns = {column : name})\n",
    "  \n",
    "  # 컬럼명 변경\n",
    "  df = df.rename(columns={'자치구별(2)_자치구별(2)' : '구'})\n",
    "  \n",
    "  # 필요없는 컬럼 삭제\n",
    "  df = df.drop(columns=0)\n",
    "  \n",
    "  #필요 없는 행 삭제\n",
    "  df = df.drop(index=[0, 1, 2, 3, 4])\n",
    "  \n",
    "  # 인덱스 리셋\n",
    "  df = df.reset_index()\n",
    "  df = df.drop(columns=['index'])\n",
    "\n",
    "  # 년도 컬럼 추가\n",
    "  df = pd.DataFrame(df)\n",
    "  df['년도'] = year\n",
    "\n",
    "  df = df.loc[1:, ['년도', '구', '합계_공원수 (개소)']]\n",
    "  return df\n",
    "\n",
    "'''\n",
    "의료기관 데이터 전처리\n",
    "'''\n",
    "def precleaning_medical(df, year) :\n",
    "  # 컬럼명 지정\n",
    "  df.columns = df.iloc[2] + '_' +  df.iloc[3]\n",
    " \n",
    "  # 쓸모없는 행 삭제\n",
    "  df = df[4:]\n",
    "  \n",
    "  # 슬모없는 열 삭제\n",
    "  df = df.drop(columns = '자치구별(1)_자치구별(1)')\n",
    "\n",
    "  if year > 2022:\n",
    "    df = df.drop(columns = '한센병원_병원수')\n",
    "    \n",
    "  # 보기쉽게 열이름 바꿈\n",
    "  df = df.rename(columns = {'자치구별(2)_자치구별(2)' : '구'})\n",
    "  condition1 = df.columns.str.contains('_병원수')\n",
    "  selected_columns = df.loc[:, condition1]  # 열 기준으로 선택\n",
    "  columns = []\n",
    "  columns.append('구')\n",
    "\n",
    "  # 데이터에 있는 병원 계열로 컬럼 지정\n",
    "  for column in selected_columns.columns :\n",
    "    columns.append(column)\n",
    "  df = df[columns]\n",
    "\n",
    "  # 행 지운 후 인덱스 초기화\n",
    "  df = df.reset_index()\n",
    "  df = df.drop(columns=['index'])\n",
    "  df['년도'] = year\n",
    "\n",
    "  df = df[['년도','구','소계_병원수']]\n",
    "  return df\n",
    "\n",
    "'''\n",
    "개발계획 데이터 전처리\n",
    "'''\n",
    "def precleaning_develop(df, year):\n",
    "  # 컬럼명 지정\n",
    "  df.columns = df.iloc[1] + '_' + df.iloc[2]\n",
    "  \n",
    "  # 불필요한 데이터 삭제\n",
    "  df = df.drop(index=[0, 1, 2])\n",
    "\n",
    "  \n",
    "  # 서울특별시 데이터만 추출\n",
    "  df = df[df['소재지(시군구)별(1)_소재지(시군구)별(1)'] == '서울특별시']\n",
    "\n",
    "  # 컬러명 변경 \n",
    "  df = df.rename(columns ={'소재지(시군구)별(2)_소재지(시군구)별(2)' : '구'})\n",
    "  df = df.rename(columns ={'소재지(시군구)별(1)_소재지(시군구)별(1)' : '-'})\n",
    "  # 인덱스 초기화\n",
    "  df = df.reset_index()\n",
    "  df = df.drop(columns=['index'])\n",
    "\n",
    "  df['년도'] = year\n",
    "  df = df.loc[1:, ['년도', '구', '계_구역수 (개)']]\n",
    "  return df\n",
    "\n",
    "'''\n",
    "건축거래 현황 데이터 전처리\n",
    "'''\n",
    "def precleaning_transaction(df, year) :\n",
    "  copy_df = df.copy()\n",
    "  copy_df.columns = copy_df.iloc[0] + '_' + copy_df.iloc[1]\n",
    "  copy_df = copy_df.iloc[2:, 1:]\n",
    "  copy_df = copy_df.rename(columns = {'행정구역별(2)_행정구역별(2)' : '구'})\n",
    "\n",
    "  condition1 = copy_df.columns.str.contains(year)\n",
    "  select_columns = copy_df.loc[:, condition1].columns\n",
    "  columns = []\n",
    "  columns.append('구')\n",
    "  for column in select_columns :\n",
    "    columns.append(column)\n",
    "  \n",
    "  selected_df = copy_df[columns]\n",
    "  # Melt 함수를 사용하여 열을 행으로 변환\n",
    "  df_melted = selected_df.melt(id_vars=['구'], var_name='월', value_name='값')\n",
    "  \n",
    "  # 월별 동(호)수와 면적을 구분하기 위해 컬럼을 분리\n",
    "  df_melted[['연도_월', '항목']] = df_melted['월'].str.split('_', expand=True)\n",
    "  \n",
    "  # 항목이 동(호)수인지 면적인지에 따라 값 분리\n",
    "  df_melted = df_melted.pivot_table(index=['구', '연도_월'], columns='항목', values='값', aggfunc='first').reset_index()\n",
    "\n",
    "  df_melted['년도'] = year\n",
    "  df_melted = df_melted.rename(columns={'동(호)수 (동(호)수)':'동(호)수'})\n",
    "  df_melted['동(호)수']    = df_melted['동(호)수'].astype(int)\n",
    "  df_melted['면적 (천㎡)'] = df_melted['면적 (천㎡)'].astype(int)\n",
    "\n",
    "  df_melted = df_melted.groupby(['년도', '구']).agg({'동(호)수': 'sum', '면적 (천㎡)': 'sum'}).reset_index()\n",
    "  df_melted = df_melted[df_melted['구'] != '소계']\n",
    "  return df_melted\n",
    "\n",
    "'''\n",
    "수급등급 전처리 함수\n",
    "'''\n",
    "def precleaning_buysell(df, year):\n",
    "  \n",
    "  df[['종로구', '중구', '용산구']] = pd.concat([df[1]] *3, axis=1).values\n",
    "  df[['성동구', '광진구', '동대문구', '중랑구', '성북구','강북구','도봉구','노원구']] = pd.concat([df[2]] *8, axis=1).values\n",
    "  df[['은평구', '서대문구', '마포구']] = pd.concat([df[3]] *3, axis=1).values\n",
    "  df[['양천구', '강서구', '구로구','금천구','영등포구','동작구','관악구']] = pd.concat([df[4]] *7, axis=1).values\n",
    "  df[['서초구', '강남구', '송파구','강동구']] = pd.concat([df[5]] *4, axis=1).values\n",
    "  df = df.drop(columns=[1,2,3,4,5])\n",
    "  df = df.drop(index=[0,1])\n",
    "  df = df.rename(columns={0 : '년월'})\n",
    "  df = df.reset_index()\n",
    "  df = df.drop(columns=['index'])\n",
    "\n",
    "  # 년월 데이터를 date화 함\n",
    "  df['년월'] = pd.to_datetime(df['년월'], errors='coerce')\n",
    "  # 년도별로 분리\n",
    "  year_df = df[df['년월'].dt.year == year]\n",
    "  return year_df\n",
    "'''\n",
    "수급동급 '구'마다 '월'단위로 수급동급 추출\n",
    "'''\n",
    "def cleaning_data(df):\n",
    "  df['년월'] = df['년월'].astype(str)\n",
    "  df['년월'] = df['년월'].str.split('-').str[1]\n",
    "  df = df.melt(id_vars=['년월'], var_name='구', value_name='수급등급')\n",
    "  df.rename(columns={'년월':'월'}, inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "'''\n",
    "주거실태 전처리 함수\n",
    "'''\n",
    "def precleaning_housereality(df, year):\n",
    "    # 년도 검색\n",
    "    category_year = df.columns.str.contains(year)\n",
    "    category_year[0] = True\n",
    "\n",
    "    # 년도 분류\n",
    "    abode_house_category_year_df = df.loc[:, category_year]\n",
    "    house_col_year = abode_house_category_year_df.loc[0].values\n",
    "    abode_house_category_year_df.columns = house_col_year\n",
    "\n",
    "    # 0행 삭제\n",
    "    abode_house_category_year_df = ManagedDataFrame('abode_house_category_' + year, abode_house_category_year_df)\n",
    "    abode_house_category_year_df.delete_row_once()\n",
    "    \n",
    "    abode_house_category_year_df = abode_house_category_year_df.df\n",
    "    abode_house_category_year_df = abode_house_category_year_df.drop(columns=[\"단독주택-일반\", \"단독주택-다가구\", \"단독주택-영업겸용\"])\n",
    "    abode_house_category_year_df = abode_house_category_year_df.rename(columns={'주택':'계'})\n",
    "    abode_house_category_year_df = abode_house_category_year_df.rename(columns={'단독주택-계':'단독주택'})\n",
    "    abode_house_category_year_df = abode_house_category_year_df.rename(columns={'비주거용 건물 내 주택':'비주거용주택'})\n",
    "    abode_house_category_year_df = abode_house_category_year_df.rename(columns={'행정구역별(읍면동)':'구'})\n",
    "    \n",
    "    abode_house_category_year_df['계']           = abode_house_category_year_df['계'].astype(int)\n",
    "    abode_house_category_year_df['단독주택']     = abode_house_category_year_df['단독주택'].astype(int)\n",
    "    abode_house_category_year_df['아파트']       = abode_house_category_year_df['아파트'].astype(int)\n",
    "    abode_house_category_year_df['연립주택']     = abode_house_category_year_df['연립주택'].astype(int)\n",
    "    abode_house_category_year_df['다세대주택']   = abode_house_category_year_df['다세대주택'].astype(int)\n",
    "    abode_house_category_year_df['비주거용주택'] = abode_house_category_year_df['비주거용주택'].astype(int)\n",
    "\n",
    "    df_year = pd.DataFrame(abode_house_category_year_df)\n",
    "    df_year['년도'] = int(year)\n",
    "\n",
    "    # '서울특별시'를 제외한 데이터만 선택\n",
    "    df_filtered = df_year[df_year['구'] != '서울특별시']\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "'''\n",
    "매매가격지수 전처리 함수\n",
    "'''\n",
    "def precleaning_priceRelative(df, year) :\n",
    "  columns = df.columns.str.contains('.1')\n",
    "  goo = df.loc[:, ~columns].columns[2:]\n",
    "  goo_1 = df.loc[:, columns].columns\n",
    "  # Wide-to-Long 변환\n",
    "  df_long = pd.melt(\n",
    "      df,\n",
    "      id_vars=[\"자료시점\"],  # 고정할 열\n",
    "      value_vars=goo,  # 변환할 열 (원자료)\n",
    "      var_name=\"구\",  # 변환 후 열 이름\n",
    "      value_name=\"원자료\",  # 값 열 이름\n",
    "  )\n",
    "  \n",
    "  # 전기대비증감률 추가\n",
    "  df_rate = pd.melt(\n",
    "      df,\n",
    "      id_vars=[\"자료시점\"],\n",
    "      value_vars=goo_1,\n",
    "      var_name=\"구\",\n",
    "      value_name=\"전기대비증감률\",\n",
    "  )\n",
    "  \n",
    "  # \"구\" 컬럼 정리\n",
    "  df_long[\"구\"] = df_long[\"구\"].str.replace(\".1\", \"\")\n",
    "  df_rate[\"구\"] = df_rate[\"구\"].str.replace(\".1\", \"\")\n",
    "  \n",
    "  # 최종 병합\n",
    "  final_df = pd.merge(df_long, df_rate, on=[\"자료시점\", \"구\"])\n",
    "  \n",
    "  # 원하는 형식으로 정렬\n",
    "  final_df = final_df[[\"자료시점\", \"구\", \"원자료\", \"전기대비증감률\"]]\n",
    "  final_df = final_df.loc[1:, :]\n",
    "  condition = final_df['자료시점'].str.contains(f\"{year}년\")\n",
    "  final_year_df = final_df.loc[condition, :]\n",
    "  final_year_df['원자료'] = final_year_df['원자료'].astype(float)\n",
    "  final_year_df['전기대비증감률'] = final_year_df['전기대비증감률'].astype(float)\n",
    "  final_year_df = final_year_df.groupby('구')[['원자료', '전기대비증감률']].mean().reset_index()\n",
    "\n",
    "  return final_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec33b0-b889-4c70-b306-48acba14ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## 전처리 함수 적용 ###################################\n",
    "\n",
    "    # 서울시 집값 전처리 함수 적용\n",
    "seoul_2015_avg_df = precleaning_seoul(seoul_2015_df)\n",
    "seoul_2016_avg_df = precleaning_seoul(seoul_2016_df)\n",
    "seoul_2017_avg_df = precleaning_seoul(seoul_2017_df)\n",
    "seoul_2018_avg_df = precleaning_seoul(seoul_2018_df)\n",
    "seoul_2019_avg_df = precleaning_seoul(seoul_2019_df)\n",
    "seoul_2020_avg_df = precleaning_seoul(seoul_2020_df)\n",
    "seoul_2021_avg_df = precleaning_seoul(seoul_2021_df)\n",
    "seoul_2022_avg_df = precleaning_seoul(seoul_2022_df)\n",
    "seoul_2023_avg_df = precleaning_seoul(seoul_2023_df)\n",
    "\n",
    "    # 유통업체 전처리 함수 적용\n",
    "distributor_2015_df = precleaning_distributor(distributor_2015_df)\n",
    "distributor_2016_df = precleaning_distributor(distributor_2016_df)\n",
    "distributor_2017_df = precleaning_distributor(distributor_2017_df)\n",
    "distributor_2018_df = precleaning_distributor(distributor_2018_df)\n",
    "distributor_2019_df = precleaning_distributor(distributor_2019_df)\n",
    "distributor_2020_df = precleaning_distributor(distributor_2020_df)\n",
    "\n",
    "distributor_2021_df = precleaning_distributor(distributor_2021_df)\n",
    "distributor_2022_df = precleaning_distributor(distributor_2022_df)\n",
    "distributor_2023_df = precleaning_distributor(distributor_2023_df)\n",
    "\n",
    "    # 버스 전처리 함수 적용\n",
    "bus_stop_2019_df = precleaning_bus(bus_stop_2019_df)\n",
    "bus_stop_2020_df = precleaning_bus(bus_stop_2020_df)\n",
    "bus_stop_2021_df = precleaning_bus(bus_stop_2021_df)\n",
    "bus_stop_2022_df = precleaning_bus(bus_stop_2022_df)\n",
    "bus_stop_2023_df = precleaning_bus(bus_stop_2023_df)\n",
    "\n",
    "    # 지하철 전처리 함수 적용\n",
    "train_2015_df.drop(columns = '연번', inplace= True)\n",
    "train_2020_df.drop(columns = '연번', inplace= True)\n",
    "train_2021_df.drop(columns = '연번', inplace= True)\n",
    "train_2022_df.drop(columns = '연번', inplace= True)\n",
    "train_2015_df = precleaning_train(train_2021_df)\n",
    "train_2020_df = precleaning_train(train_2022_df)\n",
    "train_2021_df = precleaning_train(train_2021_df)\n",
    "train_2022_df = precleaning_train(train_2022_df)\n",
    "train_2023_df = precleaning_train(train_2023_df)\n",
    "\n",
    "    # 인구수 전처리 함수 적용\n",
    "population_2015_df = precleaning_population(population_2015_2020_df, '2015')\n",
    "population_2016_df = precleaning_population(population_2015_2020_df, '2016')\n",
    "population_2017_df = precleaning_population(population_2015_2020_df, '2017')\n",
    "population_2018_df = precleaning_population(population_2015_2020_df, '2018')\n",
    "population_2019_df = precleaning_population(population_2015_2020_df, '2019')\n",
    "population_2020_df = precleaning_population(population_2015_2020_df, '2020')\n",
    "\n",
    "population_2021_df = precleaning_population(population_df, '2021')\n",
    "population_2022_df = precleaning_population(population_df, '2022')\n",
    "population_2023_df = precleaning_population(population_df, '2023')\n",
    "\n",
    "    # 공원 전처리 함수 적용\n",
    "park_2015_df = preclearning_park(park_2015_df, '2015')\n",
    "park_2016_df = preclearning_park(park_2016_df, '2016')\n",
    "park_2017_df = preclearning_park(park_2017_df, '2017')\n",
    "park_2018_df = preclearning_park(park_2018_df, '2018')\n",
    "park_2019_df = preclearning_park(park_2019_df, '2019')\n",
    "park_2020_df = preclearning_park(park_2020_df, '2020')\n",
    "\n",
    "park_2021_df = preclearning_park(park_2021_df, '2021')\n",
    "park_2022_df = preclearning_park(park_2022_df, '2022')\n",
    "park_2023_df = preclearning_park(park_2023_df, '2023')\n",
    "\n",
    "\n",
    "    # 의료기관 전처리 함수 적용\n",
    "medical_2015_df = precleaning_medical(medical_2015_df, 2015)\n",
    "medical_2016_df = precleaning_medical(medical_2016_df, 2016)\n",
    "medical_2017_df = precleaning_medical(medical_2017_df, 2017)\n",
    "medical_2018_df = precleaning_medical(medical_2018_df, 2018)\n",
    "medical_2019_df = precleaning_medical(medical_2019_df, 2019)\n",
    "medical_2020_df = precleaning_medical(medical_2020_df, 2020)\n",
    "\n",
    "medical_2021_df = precleaning_medical(medical_2021_df, 2021)\n",
    "medical_2022_df = precleaning_medical(medical_2022_df, 2022)\n",
    "medical_2023_df = precleaning_medical(medical_2023_df, 2023)\n",
    "\n",
    "\n",
    "    # 개발계획 데이터 전처리 함수 적용\n",
    "develop_2015_df=precleaning_develop(develop_2015_df, 2015)\n",
    "develop_2016_df=precleaning_develop(develop_2016_df, 2016)\n",
    "develop_2017_df=precleaning_develop(develop_2017_df, 2017)\n",
    "develop_2018_df=precleaning_develop(develop_2018_df, 2018)\n",
    "develop_2019_df=precleaning_develop(develop_2019_df, 2019)\n",
    "develop_2020_df=precleaning_develop(develop_2020_df, 2020)\n",
    "\n",
    "develop_2021_df=precleaning_develop(develop_2021_df, 2021)\n",
    "develop_2022_df=precleaning_develop(develop_2022_df, 2022)\n",
    "develop_2023_df=precleaning_develop(develop_2023_df, 2023)\n",
    "\n",
    "\n",
    "    # 건축거래 현황 전처리 함수 적용\n",
    "house_transaction_2015_df = precleaning_transaction(house_transaction_2015_2020_df, '2015')\n",
    "house_transaction_2016_df = precleaning_transaction(house_transaction_2015_2020_df, '2016')\n",
    "house_transaction_2017_df = precleaning_transaction(house_transaction_2015_2020_df, '2017')\n",
    "house_transaction_2018_df = precleaning_transaction(house_transaction_2015_2020_df, '2018')\n",
    "house_transaction_2019_df = precleaning_transaction(house_transaction_2015_2020_df, '2019')\n",
    "house_transaction_2020_df = precleaning_transaction(house_transaction_2015_2020_df, '2020')\n",
    "\n",
    "house_transaction_2021_df = precleaning_transaction(house_transaction_df, '2021')\n",
    "house_transaction_2022_df = precleaning_transaction(house_transaction_df, '2022')\n",
    "house_transaction_2023_df = precleaning_transaction(house_transaction_df, '2023')\n",
    "\n",
    "\n",
    "    # 수급동급 전처리 함수 적용\n",
    "buysell_2015_df = precleaning_buysell(buysell_2015_2020_df, 2015)\n",
    "buysell_2016_df = precleaning_buysell(buysell_2015_2020_df, 2016)\n",
    "buysell_2017_df = precleaning_buysell(buysell_2015_2020_df, 2017)\n",
    "buysell_2018_df = precleaning_buysell(buysell_2015_2020_df, 2018)\n",
    "buysell_2019_df = precleaning_buysell(buysell_2015_2020_df, 2019)\n",
    "buysell_2020_df = precleaning_buysell(buysell_2015_2020_df, 2020)\n",
    "\n",
    "buysell_2021_df = precleaning_buysell(buysell_df, 2021)\n",
    "buysell_2022_df = precleaning_buysell(buysell_df, 2022)\n",
    "buysell_2023_df = precleaning_buysell(buysell_df, 2023)\n",
    "buysell_2024_df = precleaning_buysell(buysell_df, 2024)\n",
    "# '''\n",
    "# 데이터 값이 79 이하 0, 80~120 은 1, 121~ 2 로 변경\n",
    "# '''\n",
    "# # 데이터 타입 변경\n",
    "# buysell_df.iloc[:,1:] = buysell_df.iloc[:,1:].astype(float)\n",
    "\n",
    "# \"\"\" 람다식 \n",
    "# buysell_df.iloc[:, 1:] = buysell_df.iloc[:, 1:].applymap(\n",
    "#    lambda x: 0 if x <= 79 else (1 if x <= 120 else 2)) \"\"\"\n",
    "\n",
    "# # 조건과 대응되는 값 설정\n",
    "# conditions = [\n",
    "#     (buysell_df.iloc[:, 1:] <= 79),\n",
    "#     (buysell_df.iloc[:, 1:] >= 80) & (buysell_df.iloc[:, 1:] <= 120),\n",
    "#     (buysell_df.iloc[:, 1:] >= 121)\n",
    "# ]\n",
    "# choices = [0, 1, 2]\n",
    "\n",
    "# # 조건에 따라 값 변경\n",
    "# buysell_df.iloc[:, 1:] = np.select(conditions, choices)\n",
    "\n",
    "# buysell_df\n",
    "\n",
    "# 추출 함수 실행\n",
    "buysell_2015_df = cleaning_data(buysell_2015_df)\n",
    "buysell_2016_df = cleaning_data(buysell_2016_df)\n",
    "buysell_2017_df = cleaning_data(buysell_2017_df)\n",
    "buysell_2018_df = cleaning_data(buysell_2018_df)\n",
    "buysell_2019_df = cleaning_data(buysell_2019_df)\n",
    "buysell_2020_df = cleaning_data(buysell_2020_df)\n",
    "\n",
    "buysell_2021_df = cleaning_data(buysell_2021_df)\n",
    "buysell_2022_df = cleaning_data(buysell_2022_df)\n",
    "buysell_2023_df = cleaning_data(buysell_2023_df)\n",
    "buysell_2024_df = cleaning_data(buysell_2024_df)\n",
    "\n",
    "   # 주거실태 전처리 함수 적용\n",
    "abode_house_category_2015_df = precleaning_housereality(abode_house_2015_2020_category, '2015')\n",
    "abode_house_category_2016_df = precleaning_housereality(abode_house_2015_2020_category, '2016')\n",
    "abode_house_category_2017_df = precleaning_housereality(abode_house_2015_2020_category, '2017')\n",
    "abode_house_category_2018_df = precleaning_housereality(abode_house_2015_2020_category, '2018')\n",
    "abode_house_category_2019_df = precleaning_housereality(abode_house_2015_2020_category, '2019')\n",
    "abode_house_category_2020_df = precleaning_housereality(abode_house_2015_2020_category, '2020')\n",
    "\n",
    "abode_house_category_2021_df = precleaning_housereality(abode_house_category, '2021')\n",
    "abode_house_category_2022_df = precleaning_housereality(abode_house_category, '2022')\n",
    "abode_house_category_2023_df = precleaning_housereality(abode_house_category, '2023')\n",
    "\n",
    "    # 매매가격지수 전처리 함수 적용\n",
    "priceRelative_2015_df = precleaning_priceRelative(priceRelative_2015_2020_df, '2015')\n",
    "priceRelative_2016_df = precleaning_priceRelative(priceRelative_2015_2020_df, '2016')\n",
    "priceRelative_2017_df = precleaning_priceRelative(priceRelative_2015_2020_df, '2017')\n",
    "priceRelative_2018_df = precleaning_priceRelative(priceRelative_2015_2020_df, '2018')\n",
    "priceRelative_2019_df = precleaning_priceRelative(priceRelative_2015_2020_df, '2019')\n",
    "priceRelative_2020_df = precleaning_priceRelative(priceRelative_2015_2020_df, '2020')\n",
    "\n",
    "priceRelative_2021_df = precleaning_priceRelative(priceRelative_df, '2021')\n",
    "priceRelative_2022_df = precleaning_priceRelative(priceRelative_df, '2022')\n",
    "priceRelative_2023_df = precleaning_priceRelative(priceRelative_df, '2023')\n",
    "priceRelative_2024_df = precleaning_priceRelative(priceRelative_df, '2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e918dcf-01ae-4268-9101-124ab81998ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ 전처리 적용 데이터프레임 csv 저장 ##########################\n",
    "\n",
    "# '''\n",
    "# 서울시 집값 / 부동산\n",
    "# '''\n",
    "# seoul_2015_avg_df.to_csv('전처리_부동산_2015.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2016_avg_df.to_csv('전처리_부동산_2016.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2017_avg_df.to_csv('전처리_부동산_2017.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2018_avg_df.to_csv('전처리_부동산_2018.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2019_avg_df.to_csv('전처리_부동산_2019.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2020_avg_df.to_csv('전처리_부동산_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# seoul_2021_avg_df.to_csv('전처리_부동산_2021.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2022_avg_df.to_csv('전처리_부동산_2022.csv', index = False, encoding = 'cp949')\n",
    "# seoul_2023_avg_df.to_csv('전처리_부동산_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 버스 정류장 수\n",
    "# '''\n",
    "# bus_stop_2019_df.to_csv('전처리_버스수_2019.csv', index = False, encoding = 'cp949')\n",
    "# bus_stop_2020_df.to_csv('전처리_버스수_2020.csv', index = False, encoding = 'cp949')\n",
    "# bus_stop_2021_df.to_csv('전처리_버스수_2021.csv', index = False, encoding = 'cp949')\n",
    "# bus_stop_2022_df.to_csv('전처리_버스수_2022.csv', index = False, encoding = 'cp949')\n",
    "# bus_stop_2023_df.to_csv('전처리_버스수_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 지하철 역 개수\n",
    "# '''\n",
    "# train_2015_df.to_csv('전처리_지하철수_2015.csv', index = False, encoding = 'cp949')\n",
    "# train_2020_df.to_csv('전처리_지하철수_2020.csv', index = False, encoding = 'cp949')\n",
    "# train_2021_df.to_csv('전처리_지하철수_2021.csv', index = False, encoding = 'cp949')\n",
    "# train_2022_df.to_csv('전처리_지하철수_2022.csv', index = False, encoding = 'cp949')\n",
    "# train_2023_df.to_csv('전처리_지하철수_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 공원 개수\n",
    "# '''\n",
    "# park_2015_df.to_csv('전처리_공원수_2015.csv', index = False, encoding = 'cp949')\n",
    "# park_2016_df.to_csv('전처리_공원수_2016.csv', index = False, encoding = 'cp949')\n",
    "# park_2017_df.to_csv('전처리_공원수_2017.csv', index = False, encoding = 'cp949')\n",
    "# park_2018_df.to_csv('전처리_공원수_2018.csv', index = False, encoding = 'cp949')\n",
    "# park_2019_df.to_csv('전처리_공원수_2019.csv', index = False, encoding = 'cp949')\n",
    "# park_2020_df.to_csv('전처리_공원수_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# park_2021_df.to_csv('전처리_공원수_2021.csv', index = False, encoding = 'cp949')\n",
    "# park_2022_df.to_csv('전처리_공원수_2022.csv', index = False, encoding = 'cp949')\n",
    "# park_2023_df.to_csv('전처리_공원수_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 유통업체 수\n",
    "# '''\n",
    "# distributor_2015_df.to_csv('전처리_유통업체_2015.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2016_df.to_csv('전처리_유통업체_2016.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2017_df.to_csv('전처리_유통업체_2017.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2018_df.to_csv('전처리_유통업체_2018.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2019_df.to_csv('전처리_유통업체_2019.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2020_df.to_csv('전처리_유통업체_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# distributor_2021_df.to_csv('전처리_유통업체_2021.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2022_df.to_csv('전처리_유통업체_2022.csv', index = False, encoding = 'cp949')\n",
    "# distributor_2023_df.to_csv('전처리_유통업체_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 의료기관 / 병원 수\n",
    "# '''\n",
    "# medical_2015_df.to_csv('전처리_병원수_2015.csv', index = False, encoding = 'cp949')\n",
    "# medical_2016_df.to_csv('전처리_병원수_2016.csv', index = False, encoding = 'cp949')\n",
    "# medical_2017_df.to_csv('전처리_병원수_2017.csv', index = False, encoding = 'cp949')\n",
    "# medical_2018_df.to_csv('전처리_병원수_2018.csv', index = False, encoding = 'cp949')\n",
    "# medical_2019_df.to_csv('전처리_병원수_2019.csv', index = False, encoding = 'cp949')\n",
    "# medical_2020_df.to_csv('전처리_병원수_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# medical_2021_df.to_csv('전처리_병원수_2021.csv', index = False, encoding = 'cp949')\n",
    "# medical_2022_df.to_csv('전처리_병원수_2022.csv', index = False, encoding = 'cp949')\n",
    "# medical_2023_df.to_csv('전처리_병원수_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 개발 계획\n",
    "# '''\n",
    "# develop_2015_df.to_csv('전처리_개발계획_2015.csv', index = False, encoding = 'cp949')\n",
    "# develop_2016_df.to_csv('전처리_개발계획_2016.csv', index = False, encoding = 'cp949')\n",
    "# develop_2017_df.to_csv('전처리_개발계획_2017.csv', index = False, encoding = 'cp949')\n",
    "# develop_2018_df.to_csv('전처리_개발계획_2018.csv', index = False, encoding = 'cp949')\n",
    "# develop_2019_df.to_csv('전처리_개발계획_2019.csv', index = False, encoding = 'cp949')\n",
    "# develop_2020_df.to_csv('전처리_개발계획_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# develop_2021_col.to_csv('전처리_개발계획_2021.csv', index = False, encoding = 'cp949')\n",
    "# develop_2022_col.to_csv('전처리_개발계획_2022.csv', index = False, encoding = 'cp949')\n",
    "# develop_2023_col.to_csv('전처리_개발계획_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 인구 수\n",
    "# '''\n",
    "# population_2015_df.to_csv('전처리_인구수_2015.csv', index = False, encoding = 'cp949')\n",
    "# population_2016_df.to_csv('전처리_인구수_2016.csv', index = False, encoding = 'cp949')\n",
    "# population_2017_df.to_csv('전처리_인구수_2017.csv', index = False, encoding = 'cp949')\n",
    "# population_2018_df.to_csv('전처리_인구수_2018.csv', index = False, encoding = 'cp949')\n",
    "# population_2019_df.to_csv('전처리_인구수_2019.csv', index = False, encoding = 'cp949')\n",
    "# population_2020_df.to_csv('전처리_인구수_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# population_2021_df.to_csv('전처리_인구수_2021.csv', index = False, encoding = 'cp949')\n",
    "# population_2022_df.to_csv('전처리_인구수_2022.csv', index = False, encoding = 'cp949')\n",
    "# population_2023_df.to_csv('전처리_인구수_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 주거실태 / 거래량 / 건축거래 현황\n",
    "# '''\n",
    "house_transaction_2015_df.to_csv('전처리_거래량_2015.csv', index = False, encoding = 'cp949')\n",
    "house_transaction_2016_df.to_csv('전처리_거래량_2016.csv', index = False, encoding = 'cp949')\n",
    "house_transaction_2017_df.to_csv('전처리_거래량_2017.csv', index = False, encoding = 'cp949')\n",
    "house_transaction_2018_df.to_csv('전처리_거래량_2018.csv', index = False, encoding = 'cp949')\n",
    "house_transaction_2019_df.to_csv('전처리_거래량_2019.csv', index = False, encoding = 'cp949')\n",
    "house_transaction_2020_df.to_csv('전처리_거래량_2020.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# house_transaction_2021_df.to_csv('전처리_거래량_2021.csv', index = False, encoding = 'cp949')\n",
    "# house_transaction_2022_df.to_csv('전처리_거래량_2022.csv', index = False, encoding = 'cp949')\n",
    "# house_transaction_2023_df.to_csv('전처리_거래량_2023.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# '''\n",
    "# 수요/공급 지수 \n",
    "# '''\n",
    "# buysell_2015_df.to_csv('전처리_수요공급지수_2015.csv', index=False, encoding='cp949')\n",
    "# buysell_2016_df.to_csv('전처리_수요공급지수_2016.csv', index=False, encoding='cp949')\n",
    "# buysell_2017_df.to_csv('전처리_수요공급지수_2017.csv', index=False, encoding='cp949')\n",
    "# buysell_2018_df.to_csv('전처리_수요공급지수_2018.csv', index=False, encoding='cp949')\n",
    "# buysell_2019_df.to_csv('전처리_수요공급지수_2019.csv', index=False, encoding='cp949')\n",
    "# buysell_2020_df.to_csv('전처리_수요공급지수_2020.csv', index=False, encoding='cp949')\n",
    "\n",
    "# buysell_2021_df.to_csv('전처리_수요공급지수_2021.csv', index=False, encoding='cp949')\n",
    "# buysell_2022_df.to_csv('전처리_수요공급지수_2022.csv', index=False, encoding='cp949')\n",
    "# buysell_2023_df.to_csv('전처리_수요공급지수_2023.csv', index=False, encoding='cp949')\n",
    "# buysell_2024_df.to_csv('전처리_수요공급지수_2024.csv', index=False, encoding='cp949')\n",
    "\n",
    "# '''\n",
    "# 주거실태\n",
    "# '''\n",
    "# abode_house_category_2015_df.to_csv('전처리_주거실태_2015.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2016_df.to_csv('전처리_주거실태_2016.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2017_df.to_csv('전처리_주거실태_2017.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2018_df.to_csv('전처리_주거실태_2018.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2019_df.to_csv('전처리_주거실태_2019.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2020_df.to_csv('전처리_주거실태_2020.csv', index=False, encoding='cp949')\n",
    "\n",
    "# abode_house_category_2021_df.to_csv('전처리_주거실태_2021.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2022_df.to_csv('전처리_주거실태_2022.csv', index=False, encoding='cp949')\n",
    "# abode_house_category_2023_df.to_csv('전처리_주거실태_2023.csv', index=False, encoding='cp949')\n",
    "\n",
    "# '''\n",
    "# 매매가격지수\n",
    "# '''\n",
    "# priceRelative_2015_df.to_csv('전처리_매매가격지수_2015.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2016_df.to_csv('전처리_매매가격지수_2016.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2017_df.to_csv('전처리_매매가격지수_2017.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2018_df.to_csv('전처리_매매가격지수_2018.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2019_df.to_csv('전처리_매매가격지수_2019.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2020_df.to_csv('전처리_매매가격지수_2020.csv', index=False, encoding='cp949')\n",
    "\n",
    "# priceRelative_2021_df.to_csv('전처리_매매가격지수_2021.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2022_df.to_csv('전처리_매매가격지수_2022.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2023_df.to_csv('전처리_매매가격지수_2023.csv', index=False, encoding='cp949')\n",
    "# priceRelative_2024_df.to_csv('전처리_매매가격지수_2024.csv', index=False, encoding='cp949')\n",
    "print('...완료..!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0794cc-e1a2-4d95-827c-38d1c2fd468b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
